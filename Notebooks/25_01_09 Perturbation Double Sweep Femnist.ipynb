{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perturbation Double Sweep\n",
    "TJ Kim\n",
    "\n",
    "1.6.22 \n",
    "\n",
    "#### Summary:\n",
    "- Sweep both Linf norm [0,1,0.5,1.0,2.0,4.0] for defense and attack\n",
    "- Generate tables for adv_acc, adv_target, adv_miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/ubuntu/FedEM/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import General Libraries\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import FedEM based Libraries\n",
    "from utils.utils import *\n",
    "from utils.constants import *\n",
    "from utils.args import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from run_experiment import *\n",
    "from models import *\n",
    "\n",
    "# Import Transfer Attack\n",
    "from transfer_attacks.Personalized_NN import *\n",
    "from transfer_attacks.Params import *\n",
    "from transfer_attacks.Transferer import *\n",
    "from transfer_attacks.Args import *\n",
    "\n",
    "from transfer_attacks.TA_utils import *\n",
    "from transfer_attacks.Boundary_Transferer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function - Calculate Mean without Diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform np.mean without the diagonal\n",
    "def avg_nondiag(array2d):\n",
    "    d1 = array2d.shape[0]\n",
    "    d2 = array2d.shape[1]\n",
    "    \n",
    "    counter = 0\n",
    "    val = 0\n",
    "    \n",
    "    for i1 in range(d1):\n",
    "        for i2 in range(d2):\n",
    "            if i1 != i2:\n",
    "                counter+=1\n",
    "                val += array2d[i1,i2]\n",
    "    \n",
    "    return val/counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Dummy Aggregator and Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Clients initialization..\n",
      "===> Building data iterators..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 719/719 [00:01<00:00, 454.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Initializing clients..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 719/719 [00:33<00:00, 21.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Test Clients initialization..\n",
      "===> Building data iterators..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Initializing clients..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 4.151 | Train Acc: 1.472% |Test Loss: 4.147 | Test Acc: 1.434% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "# Manually set argument parameters\n",
    "args_ = Args()\n",
    "args_.experiment = \"femnist\"\n",
    "args_.method = \"FedAvg_adv\"\n",
    "args_.decentralized = False\n",
    "args_.sampling_rate = 1.0\n",
    "args_.input_dimension = None\n",
    "args_.output_dimension = None\n",
    "args_.n_learners= 1\n",
    "args_.n_rounds = 10\n",
    "args_.bz = 128\n",
    "args_.local_steps = 1\n",
    "args_.lr_lambda = 0\n",
    "args_.lr =0.03\n",
    "args_.lr_scheduler = 'multi_step'\n",
    "args_.log_freq = 10\n",
    "args_.device = 'cuda'\n",
    "args_.optimizer = 'sgd'\n",
    "args_.mu = 0\n",
    "args_.communication_probability = 0.1\n",
    "args_.q = 1\n",
    "args_.locally_tune_clients = False\n",
    "args_.seed = 1234\n",
    "args_.verbose = 1\n",
    "args_.save_path = 'weights/cifar/22_01_09_fedavg_n80_benign/'\n",
    "args_.validation = False\n",
    "args_.num_user = 80\n",
    "\n",
    "# Generate the dummy values here\n",
    "aggregator, clients = dummy_aggregator(args_, num_user=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset From Client Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Validation Data across all clients as test\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for i in range(len(clients)):\n",
    "    daniloader = clients[i].val_iterator\n",
    "    for (x,y,idx) in daniloader.dataset:\n",
    "        data_x.append(x)\n",
    "        data_y.append(y)\n",
    "\n",
    "data_x = torch.stack(data_x)\n",
    "data_y = torch.tensor(data_y)\n",
    "\n",
    "# Create dataloader from validation dataset that allows for diverse batch size\n",
    "dataloader = Custom_Dataloader(data_x, data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Experiment Name Information\n",
    "\n",
    "Used later to loop through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_names = ['weights/final/femnist/fig1_take2/FedEM_Benign/', 'weights/femnist/ep_sweep/fedem_defend_ep01/',\n",
    "#              'weights/femnist/ep_sweep/fedem_defend_ep02/', 'weights/femnist/ep_sweep/fedem_defend_ep04/']\n",
    "\n",
    "exp_names = ['weights/final/femnist/fig1_take2/FedAvg_Benign/',\n",
    "             'weights/femnist/ep_sweep_fedavg/fedavg_defend_ep01/',\n",
    "             'weights/femnist/ep_sweep_fedavg/fedavg_defend_ep02/',\n",
    "             'weights/femnist/ep_sweep_fedavg/fedavg_defend_ep04/']\n",
    "\n",
    "# base = 'weights/cifar/'\n",
    "train_item = 'train_client_weights.npy'\n",
    "\n",
    "# Attack Perturbation Amount\n",
    "atk_eps = [0, 0.1, 0.5, 1.0, 2.0, 4.0, 5, 6, 7, 8.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Measurement Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_victims = 10\n",
    "num_exp = len(exp_names)\n",
    "# Set Up Dictionaries -- list holds the adversary idx\n",
    "exp_logs = {}\n",
    "\n",
    "for j in range(num_exp):\n",
    "    logs_adv = []\n",
    "\n",
    "    for i in range(num_victims):\n",
    "        adv_dict = {}\n",
    "        adv_dict['orig_acc_transfers'] = None\n",
    "        adv_dict['orig_similarities'] = None\n",
    "        adv_dict['adv_acc_transfers'] = None\n",
    "        adv_dict['adv_similarities_target'] = None\n",
    "        adv_dict['adv_similarities_untarget'] = None\n",
    "        adv_dict['adv_target'] = None\n",
    "        adv_dict['adv_miss'] = None\n",
    "        adv_dict['metric_alignment'] = None\n",
    "        adv_dict['ib_distance_legit'] = None\n",
    "        adv_dict['ib_distance_adv'] = None\n",
    "        \n",
    "        logs_adv += [adv_dict]\n",
    "    \n",
    "    exp_logs[j] = logs_adv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate extra set of exp_logs one for each perturbation\n",
    "exp_logs_list = []\n",
    "\n",
    "for i in range(len(atk_eps)):\n",
    "    exp_logs_list += [copy.deepcopy(exp_logs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Each Model and Perform Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file weights/final/femnist/fig1_take2/FedAvg_Benign/ ...\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "processing file weights/femnist/ep_sweep_fedavg/fedavg_defend_ep01/ ...\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "processing file weights/femnist/ep_sweep_fedavg/fedavg_defend_ep02/ ...\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "processing file weights/femnist/ep_sweep_fedavg/fedavg_defend_ep04/ ...\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n"
     ]
    }
   ],
   "source": [
    "# Inter Boundary Distance Metric\n",
    "num_trials = 50\n",
    "custom_batch_size = 500\n",
    "weights_save = []\n",
    "\n",
    "for j in range(num_exp):\n",
    "    print('processing file', exp_names[j], '...')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Change name if need be\n",
    "    args_.save_path = exp_names[j]\n",
    "\n",
    "    # Import weights for aggregator\n",
    "    aggregator.load_state(args_.save_path)\n",
    "\n",
    "    # This is where the models are stored -- one for each mixture --> learner.model for nn\n",
    "    hypotheses = aggregator.global_learners_ensemble.learners\n",
    "\n",
    "    # obtain the state dict for each of the weights \n",
    "    weights_h = []\n",
    "\n",
    "    for h in hypotheses:\n",
    "        weights_h += [h.model.state_dict()]\n",
    "        \n",
    "    weight_name = args_.save_path + train_item\n",
    "    weights = np.load(weight_name)\n",
    "    np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})\n",
    "\n",
    "    # Set model weights\n",
    "    model_weights = []\n",
    "    num_models = num_victims\n",
    "\n",
    "    for i in range(num_models):\n",
    "        model_weights += [weights[i]]\n",
    "\n",
    "    weights_save += [model_weights]\n",
    "        \n",
    "    # Generate the weights to test on as linear combinations of the model_weights\n",
    "    models_test = []\n",
    "\n",
    "#     for (w0, w1, w2) in model_weights:\n",
    "#         # first make the model with empty weights\n",
    "#         new_model = copy.deepcopy(hypotheses[0].model)\n",
    "#         new_model.eval()\n",
    "#         new_weight_dict = copy.deepcopy(weights_h[0])\n",
    "#         for key in weights_h[0]:\n",
    "#             new_weight_dict[key] = w0*weights_h[0][key] + w1*weights_h[1][key] + w2*weights_h[2][key] \n",
    "#         new_model.load_state_dict(new_weight_dict)\n",
    "#         models_test += [new_model]\n",
    "\n",
    "    for (w0) in model_weights:\n",
    "        # first make the model with empty weights\n",
    "        new_model = copy.deepcopy(hypotheses[0].model)\n",
    "        new_model.eval()\n",
    "        new_weight_dict = copy.deepcopy(weights_h[0])\n",
    "        for key in weights_h[0]:\n",
    "            new_weight_dict[key] = w0[0]*weights_h[0][key] \n",
    "        new_model.load_state_dict(new_weight_dict)\n",
    "        models_test += [new_model]\n",
    "    \n",
    "    for ep_idx in range(len(atk_eps)):\n",
    "        # Run Measurements for both targetted and untargeted analysis\n",
    "        victim_idxs = range(num_victims)\n",
    "\n",
    "        \n",
    "\n",
    "#         t2 = Boundary_Transferer(models_list=models_test, dataloader=dataloader)\n",
    "#         t2.victim_idx = victim_idxs\n",
    "\n",
    "        for adv_idx in victim_idxs:\n",
    "            print(\"\\t Adv idx:\", adv_idx)\n",
    "            # Perform Attacks\n",
    "            \n",
    "            dataloader2 = load_client_data(clients = clients, c_id = adv_idx, mode = 'test') # or test/train\n",
    "            batch_size = min(custom_batch_size, dataloader2.y_data.shape[0])\n",
    "            t1 = Transferer(models_list=models_test, dataloader=dataloader2)\n",
    "            t1.generate_victims(victim_idxs)\n",
    "            \n",
    "            t1.atk_params = PGD_Params()\n",
    "            t1.atk_params.set_params(batch_size=batch_size, iteration = 10,\n",
    "                           target = 5, x_val_min = torch.min(data_x), x_val_max = torch.max(data_x),\n",
    "                           step_size = 0.05, step_norm = \"inf\", eps = atk_eps[ep_idx], eps_norm = 2)\n",
    "\n",
    "            t1.generate_advNN(adv_idx)\n",
    "            t1.generate_xadv(atk_type = \"pgd\")\n",
    "            t1.send_to_victims(victim_idxs)\n",
    "            # t1.check_empirical_metrics(orig_flag = True)\n",
    "\n",
    "            # Log Performance\n",
    "            exp_logs_list[ep_idx][j][adv_idx]['orig_acc_transfers'] = copy.deepcopy(t1.orig_acc_transfers)\n",
    "            exp_logs_list[ep_idx][j][adv_idx]['orig_similarities'] = copy.deepcopy(t1.orig_similarities)\n",
    "            exp_logs_list[ep_idx][j][adv_idx]['adv_acc_transfers'] = copy.deepcopy(t1.adv_acc_transfers)\n",
    "            exp_logs_list[ep_idx][j][adv_idx]['adv_similarities_target'] = copy.deepcopy(t1.adv_similarities)        \n",
    "            exp_logs_list[ep_idx][j][adv_idx]['adv_target'] = copy.deepcopy(t1.adv_target_hit)\n",
    "            # exp_logs_list[ep_idx][j][adv_idx]['metric_alignment'] = copy.deepcopy(t1.metric_alignment)\n",
    "\n",
    "            # Miss attack\n",
    "            t1.atk_params.set_params(batch_size=batch_size, iteration = 10,\n",
    "                           target = -1, x_val_min = torch.min(data_x), x_val_max = torch.max(data_x),\n",
    "                           step_size = 0.05, step_norm = \"inf\", eps = atk_eps[ep_idx], eps_norm = 2)\n",
    "            t1.generate_xadv(atk_type = \"pgd\")\n",
    "            t1.send_to_victims(victim_idxs)\n",
    "            exp_logs_list[ep_idx][j][adv_idx]['adv_miss'] = copy.deepcopy(t1.adv_acc_transfers)\n",
    "            exp_logs_list[ep_idx][j][adv_idx]['adv_similarities_untarget'] = copy.deepcopy(t1.adv_similarities)\n",
    "        \n",
    "        del t1\n",
    "\n",
    "    del models_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain Metric Values and Make Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a pandas table across double sweep from list\n",
    "def make_metric_table(exp_list, metric, row_names, col_names, avg_diag_flag = True):\n",
    "    \n",
    "    num_col1 = len(exp_list)\n",
    "    num_col2 = len(exp_list[0])\n",
    "    num_victims = len(exp_list[0][0])\n",
    "    victim_idxs = range(num_victims)\n",
    "    exp_values = {}\n",
    "    \n",
    "    final_table = np.zeros([num_col1, num_col2])\n",
    "    \n",
    "    for j in range(num_col1): # Attack perturbation amount\n",
    "        for k in range(num_col2): # Defense perturbation amount (Experiment)\n",
    "            orig_vals = np.zeros([num_victims, num_victims])\n",
    "            \n",
    "            for adv_idx in range(num_victims):\n",
    "                for victim in range(num_victims):\n",
    "                    curr_list = exp_list[j][k]\n",
    "                    orig_vals[adv_idx,victim] = curr_list[victim_idxs[adv_idx]][metric][victim_idxs[victim]].data.tolist()\n",
    "            \n",
    "            if avg_diag_flag:\n",
    "                final_table[j,k] = avg_nondiag(orig_vals)\n",
    "            else:\n",
    "                final_table[j,k] = np.mean(orig_vals)\n",
    "    \n",
    "    df = pd.DataFrame(final_table, columns = col_names, index = row_names)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['orig_acc_transfers','orig_similarities','adv_acc_transfers','adv_similarities_target',\n",
    "           'adv_similarities_untarget','adv_target','adv_miss'] #,'metric_alignment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adv_miss\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D ep0.0</th>\n",
       "      <th>D ep0.1</th>\n",
       "      <th>D ep0.2</th>\n",
       "      <th>D ep0.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A ep0</th>\n",
       "      <td>0.803970</td>\n",
       "      <td>0.797203</td>\n",
       "      <td>0.801249</td>\n",
       "      <td>0.806607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A ep0.1</th>\n",
       "      <td>0.800845</td>\n",
       "      <td>0.797203</td>\n",
       "      <td>0.801249</td>\n",
       "      <td>0.802342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A ep0.5</th>\n",
       "      <td>0.789796</td>\n",
       "      <td>0.788772</td>\n",
       "      <td>0.789185</td>\n",
       "      <td>0.792672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A ep1.0</th>\n",
       "      <td>0.771385</td>\n",
       "      <td>0.783701</td>\n",
       "      <td>0.779956</td>\n",
       "      <td>0.781825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A ep2.0</th>\n",
       "      <td>0.701844</td>\n",
       "      <td>0.754433</td>\n",
       "      <td>0.765370</td>\n",
       "      <td>0.766500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A ep4.0</th>\n",
       "      <td>0.494685</td>\n",
       "      <td>0.601633</td>\n",
       "      <td>0.666113</td>\n",
       "      <td>0.701541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A ep5.0</th>\n",
       "      <td>0.357730</td>\n",
       "      <td>0.486161</td>\n",
       "      <td>0.582515</td>\n",
       "      <td>0.652475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A ep6.0</th>\n",
       "      <td>0.216378</td>\n",
       "      <td>0.346778</td>\n",
       "      <td>0.484234</td>\n",
       "      <td>0.558029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A ep7.0</th>\n",
       "      <td>0.111476</td>\n",
       "      <td>0.209267</td>\n",
       "      <td>0.383931</td>\n",
       "      <td>0.499058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A ep8.0</th>\n",
       "      <td>0.057844</td>\n",
       "      <td>0.158316</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.457116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          D ep0.0   D ep0.1   D ep0.2   D ep0.3\n",
       "A ep0    0.803970  0.797203  0.801249  0.806607\n",
       "A ep0.1  0.800845  0.797203  0.801249  0.802342\n",
       "A ep0.5  0.789796  0.788772  0.789185  0.792672\n",
       "A ep1.0  0.771385  0.783701  0.779956  0.781825\n",
       "A ep2.0  0.701844  0.754433  0.765370  0.766500\n",
       "A ep4.0  0.494685  0.601633  0.666113  0.701541\n",
       "A ep5.0  0.357730  0.486161  0.582515  0.652475\n",
       "A ep6.0  0.216378  0.346778  0.484234  0.558029\n",
       "A ep7.0  0.111476  0.209267  0.383931  0.499058\n",
       "A ep8.0  0.057844  0.158316  0.324200  0.457116"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_names = ['A ep0','A ep0.1', 'A ep0.5', 'A ep1.0', 'A ep2.0',\n",
    "             'A ep4.0', 'A ep5.0','A ep6.0', 'A ep7.0','A ep8.0']\n",
    "col_names = ['D ep0.0', 'D ep0.1', 'D ep0.2', 'D ep0.3']\n",
    "# col_names = ['G0','G0.5','G1']\n",
    "# col_names = ['FedAvg G0']\n",
    "\n",
    "name = 'adv_miss'\n",
    "print(name)\n",
    "make_metric_table(exp_logs_list, name, row_names, col_names, avg_diag_flag = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adv_target\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D ep0.0</th>\n",
       "      <th>D ep0.1</th>\n",
       "      <th>D ep0.2</th>\n",
       "      <th>D ep0.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A ep0</th>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.007027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A ep0.1</th>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.007027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A ep0.5</th>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.007027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A ep1.0</th>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.008476</td>\n",
       "      <td>0.008476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A ep2.0</th>\n",
       "      <td>0.013675</td>\n",
       "      <td>0.009925</td>\n",
       "      <td>0.008476</td>\n",
       "      <td>0.008476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A ep4.0</th>\n",
       "      <td>0.040791</td>\n",
       "      <td>0.029734</td>\n",
       "      <td>0.019799</td>\n",
       "      <td>0.018350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A ep5.0</th>\n",
       "      <td>0.098728</td>\n",
       "      <td>0.056590</td>\n",
       "      <td>0.042549</td>\n",
       "      <td>0.039073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A ep6.0</th>\n",
       "      <td>0.234105</td>\n",
       "      <td>0.114627</td>\n",
       "      <td>0.068915</td>\n",
       "      <td>0.059740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A ep7.0</th>\n",
       "      <td>0.326191</td>\n",
       "      <td>0.189736</td>\n",
       "      <td>0.112720</td>\n",
       "      <td>0.083893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A ep8.0</th>\n",
       "      <td>0.350001</td>\n",
       "      <td>0.190412</td>\n",
       "      <td>0.119902</td>\n",
       "      <td>0.080257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          D ep0.0   D ep0.1   D ep0.2   D ep0.3\n",
       "A ep0    0.009110  0.007027  0.007027  0.007027\n",
       "A ep0.1  0.009110  0.007027  0.007027  0.007027\n",
       "A ep0.5  0.009110  0.007027  0.007027  0.007027\n",
       "A ep1.0  0.009110  0.007027  0.008476  0.008476\n",
       "A ep2.0  0.013675  0.009925  0.008476  0.008476\n",
       "A ep4.0  0.040791  0.029734  0.019799  0.018350\n",
       "A ep5.0  0.098728  0.056590  0.042549  0.039073\n",
       "A ep6.0  0.234105  0.114627  0.068915  0.059740\n",
       "A ep7.0  0.326191  0.189736  0.112720  0.083893\n",
       "A ep8.0  0.350001  0.190412  0.119902  0.080257"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'adv_target'\n",
    "print(name)\n",
    "make_metric_table(exp_logs_list, name, row_names, col_names, avg_diag_flag = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_save[0] # Regular Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_save[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_save[2] # Adv Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_save[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FedEM_env",
   "language": "python",
   "name": "fedem_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
